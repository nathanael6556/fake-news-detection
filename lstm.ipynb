{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **LSTM**"
      ],
      "metadata": {
        "id": "NLh8kF9DgW-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JLekFUG6HT0",
        "outputId": "eddd7d92-dd0c-483f-c76a-927d02284132"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7pP6bdT6AJ2",
        "outputId": "070fc095-6969-4571-b5b7-4e13fe201142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 338ms/step - accuracy: 0.8342 - loss: 0.3991 - val_accuracy: 0.9200 - val_loss: 0.2048\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 331ms/step - accuracy: 0.9222 - loss: 0.2190 - val_accuracy: 0.9200 - val_loss: 0.2268\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 332ms/step - accuracy: 0.9313 - loss: 0.2109 - val_accuracy: 0.9210 - val_loss: 0.2116\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 329ms/step - accuracy: 0.9267 - loss: 0.2086 - val_accuracy: 0.9220 - val_loss: 0.2075\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 328ms/step - accuracy: 0.9353 - loss: 0.1932 - val_accuracy: 0.9280 - val_loss: 0.2112\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9218 - loss: 0.2201\n",
            "Test Accuracy: 92.80%\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 100ms/step\n",
            "[[935  65]\n",
            " [ 79 921]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93      1000\n",
            "           1       0.93      0.92      0.93      1000\n",
            "\n",
            "    accuracy                           0.93      2000\n",
            "   macro avg       0.93      0.93      0.93      2000\n",
            "weighted avg       0.93      0.93      0.93      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import pickle\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('/content/drive/MyDrive/data/elongated_word_10k.csv')\n",
        "X = data['news']\n",
        "y = data['is_fake']\n",
        "\n",
        "# Preprocess the text data with Tokenizer\n",
        "tokenizer = Tokenizer(num_words=256)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_tokenized = tokenizer.texts_to_sequences(X)\n",
        "X_padded = pad_sequences(X_tokenized, maxlen=256)\n",
        "\n",
        "# train test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_padded, y, test_size=0.2, random_state=21, stratify=y\n",
        ")\n",
        "\n",
        "# model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(layer = Embedding(input_dim = 256, output_dim = 256))\n",
        "lstm_model.add(layer = LSTM(units = 256, dropout = 0.15, recurrent_dropout = 0.15))\n",
        "lstm_model.add(layer = Dropout(rate = 0.4))\n",
        "lstm_model.add(layer = Dense(1,  activation = 'sigmoid'))\n",
        "lstm_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# predict\n",
        "lstm_model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "# evaluation\n",
        "loss, accuracy = lstm_model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# confusion matrix\n",
        "y_pred = (lstm_model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "cfm = confusion_matrix(y_test, y_pred)\n",
        "print(cfm)\n",
        "\n",
        "# report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# save model\n",
        "model_pkl_file = \"/content/drive/MyDrive/data/lstm_model.pkl\"\n",
        "\n",
        "with open(model_pkl_file, 'wb') as file:\n",
        "    pickle.dump(lstm_model, file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/data/lstm_model.pkl', 'rb') as f:\n",
        "    lstm_model = pickle.load(f)\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/data/val_10k.csv')\n",
        "X = data['news']\n",
        "y = data['is_fake']\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=256)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_tokenized = tokenizer.texts_to_sequences(X)\n",
        "X_padded = pad_sequences(X_tokenized, maxlen=256)\n",
        "\n",
        "loss, accuracy = lstm_model.evaluate(X_padded, y)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "y_pred = (lstm_model.predict(X_padded) > 0.5).astype(\"int32\")\n",
        "cfm = confusion_matrix(y, y_pred)\n",
        "print(cfm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY8h480bfp7H",
        "outputId": "79766490-a31d-4af6-9566-307c9dcee08c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 112ms/step - accuracy: 0.7206 - loss: 0.9877\n",
            "Test Accuracy: 71.94%\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 112ms/step\n",
            "[[4373  356]\n",
            " [2450 2821]]\n"
          ]
        }
      ]
    }
  ]
}